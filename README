PRE-REQS
#Install the confluent package in your home directory ("~/"): http://docs.confluent.io/2.0.1/installation.html#installation-archive
#Install dse in your home directory: http://docs.datastax.com/en/datastax_enterprise/4.8/datastax_enterprise/install/installTARdse.html
#Install pip: https://pip.pypa.io/en/stable/installing/
#optional: Install, setup, and enter a virtualenv when running python code: http://docs.python-guide.org/en/latest/dev/virtualenvs/

#Install python dependencies (virtualenv recommended)
pip install requests
pip install json

#Install confluent python library (virtualenv recommended): https://github.com/verisign/python-confluent-schemaregistry

#USAGE
#The following instructions assume you are in the energy_iot/ directory

#SETUP
#Start dse
scripts/startdse.sh

#Start Kafka components in a new window or screen
scripts/starkafka.sh

#Run simulator (generates REST calls to Kafka and runs DSE analytics code to insert values into DSE)
scripts/simulate_sensor_writes.sh <topic name> <number of sensors> <time interval>

#For example, the following inserts one reading into a topic named "meter_readings" for 100 sensors every 15 minutes:
scripts/simulate_sensor_writes.sh meter_readings 100 900

#Run the batch job
scripts/runbatch.sh

#You can verify the data is in the tables in cql:
> USE metrics;
> SELECT * FROM metrics LIMIT 100;
> SELECT * FROM metrics WHERE device_id='1';
